{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "from glob import glob\n",
    "from os import path\n",
    "from pprint import pprint\n",
    "\n",
    "from tf.fabric import Timestamp\n",
    "\n",
    "tm = Timestamp()\n",
    "\n",
    "REPO = '~/github/pthu/patristics'\n",
    "SRC_DIR = SRC_DIR = path.expanduser(f'{REPO}/sources') #/sourcetexts')\n",
    "\n",
    "authorRE = re.compile(r'<author>|<author .+?>') #[^>]*?(.+)</author>')\n",
    "editorRE = re.compile(r'<editor>|<editor .+?>') #[^>]*?(.+)</editor>')\n",
    "titleRE = re.compile(r'<title>|<title .+?>')    #[^>]*?(.+)</title>')\n",
    "bodyRE = re.compile(r'</*body>|</*body .+?>') \n",
    "\n",
    "# RE PATTERNS BODY\n",
    "openTagRE = re.compile(r'<[^/= ]+?>')\n",
    "closeTagRE = re.compile(r'</.+?>')\n",
    "opencloseTagRE = re.compile(r'<[^=/]+?/>')\n",
    "openAttrTagRE = re.compile(r'<.+?=.*?[^/]>')\n",
    "closedAttrTagRE = re.compile(r'<.+?=.*?/>')\n",
    "commentFullRE = re.compile(r'^<!--.*?-->$')\n",
    "commentStartRE = re.compile(r'^<!--.*')\n",
    "commentStopRE = re.compile(r'.*-->$')\n",
    "\n",
    "result_set = set()\n",
    "COUNTER = 0\n",
    "COUNTER2 = 0\n",
    "\n",
    "def authorWork(path):\n",
    "    author = None\n",
    "    editor = None\n",
    "    book = None\n",
    "    afound = False\n",
    "    efound = False\n",
    "    bfound = False\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if authorRE.search(line) and afound == False:\n",
    "                author = ''.join(re.split(r\"<[^>]+?>\", line)).strip('{ ,.}')\n",
    "                afound = True\n",
    "            if editorRE.search(line) and efound == False:\n",
    "                editor = ''.join(re.split(r\"<[^>]+?>\", line)).strip('{ ,.}')\n",
    "                efound = True\n",
    "            if titleRE.search(line) and bfound == False:\n",
    "                book = ''.join(re.split(r\"<[^>]+?>\", line)).strip('{ ,.}')\n",
    "                bfound = True\n",
    "            if bodyRE.search(line):\n",
    "                if author == None:\n",
    "                    author = editor\n",
    "                break\n",
    "    result_set.add((author, book))\n",
    "#     return (author work)\n",
    "\n",
    "def refsDecl(path):\n",
    "    global COUNTER2\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        found = False\n",
    "        \n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if found == True:\n",
    "                print(line)\n",
    "            if re.search(r'<refsDecl', line):\n",
    "                found = True\n",
    "                print(line)\n",
    "            if re.search(r'</refsDecl', line):\n",
    "                print(line)\n",
    "                break\n",
    "        if found == False:\n",
    "            result_set.add(path)\n",
    "            COUNTER2 +=1\n",
    "\n",
    "def cRefPattern(path):\n",
    "    global COUNTER2\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        found = False\n",
    "        \n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if found == True:\n",
    "                print(line)\n",
    "            if re.search(r'<cRefPattern', line):\n",
    "                found = True\n",
    "                print(line)\n",
    "            if re.search(r'</cRefPattern', line):\n",
    "                print(line)\n",
    "                break\n",
    "            if re.search(r'</refsDecl', line):\n",
    "                break\n",
    "        if found == False:\n",
    "            result_set.add(path)\n",
    "            COUNTER2 +=1\n",
    "            \n",
    "def state(path):\n",
    "    global COUNTER2\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        found = False\n",
    "        \n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if found == True:\n",
    "                print(line)\n",
    "            if re.search(r'<state', line):\n",
    "                found = True\n",
    "                print(line)\n",
    "            if re.search(r'</state', line):\n",
    "                print(line)\n",
    "                break\n",
    "            if re.search(r'</refsDecl', line):\n",
    "                break\n",
    "        if found == False:\n",
    "            result_set.add(path)\n",
    "            COUNTER2 +=1\n",
    "            \n",
    "def step(path):\n",
    "    global COUNTER2\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        found = False\n",
    "        \n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if found == True:\n",
    "#                 tag_split = line.find(\" \")\n",
    "                result_set.add(line)\n",
    "                result_set.add(path)\n",
    "            if re.search(r'<step', line):\n",
    "                found = True\n",
    "                result_set.add(line)\n",
    "            if re.search(r'</refsDecl', line):\n",
    "                break\n",
    "        if found == False:\n",
    "#             result_set.add(path)\n",
    "            COUNTER2 +=1\n",
    "            \n",
    "def findRefDecl(path):\n",
    "    global COUNTER2\n",
    "    with open(path, encoding='utf-8') as xml:\n",
    "        found = False\n",
    "        \n",
    "        for x in xml:\n",
    "            line = x.strip()\n",
    "            if found == True:\n",
    "#                 tag_split = line.find(\" \")\n",
    "                result_set.add(line)\n",
    "            if re.search(r'<refsDecl', line):\n",
    "                found = True\n",
    "#                 print(line)\n",
    "            if re.search(r'</refsDecl', line):\n",
    "                break\n",
    "        if found == False:\n",
    "            result_set.add(path)\n",
    "            COUNTER2 +=1\n",
    "\n",
    "def readfile(path):\n",
    "    with open(path) as xml:\n",
    "    # 16 sec\n",
    "#         data = [line.strip().split() for line in xml.readlines()]\n",
    "    # 2,89 sec\n",
    "#         data = xml.readlines()\n",
    "    # 3,34 sec\n",
    "#         data = xml.read()\n",
    "    # 5,99 sec\n",
    "#         data = xml.readlines().replace('\\n', ' ').replace(\"<\", \"#!#<\").replace(\">\", \">#!#\").split(\"#!#\")\n",
    "    # 7,25 sec\n",
    "        data = ' '.join([line.strip() for line in xml.readlines()])\\\n",
    "                        .replace(\"<\", \"#!#<\")\\\n",
    "                        .replace(\">\", \">#!#\")\\\n",
    "                        .split(\"#!#\")\n",
    "        \n",
    "    # 17 sec\n",
    "#         data = re.sub(r'\\s+\\s+', ' ', xml.read().replace('\\n', ' ').replace(\"<\", \"#!#<\").replace(\">\", \">#!#\")).split(\"#!#\")\n",
    "\n",
    "def findDivs(path):\n",
    "    global COUNTER2\n",
    "    global result_set\n",
    "    with open(path) as xml:\n",
    "        data = ' '.join([line.strip() for line in xml.readlines()])\\\n",
    "                        .replace(\"<\", \"#!#<\")\\\n",
    "                        .replace(\">\", \">#!#\")\\\n",
    "                        .split(\"#!#\")\n",
    "        for elem in data:\n",
    "            if elem.startswith('<div'):\n",
    "                result_set.add(elem)\n",
    "                COUNTER2 +=1\n",
    "                \n",
    "def findOpenTags(path):\n",
    "    TagRE = re.compile(r'<[^/]+?>')\n",
    "    global COUNTER2\n",
    "    global result_set\n",
    "    with open(path) as xml:\n",
    "        data = ' '.join([line.strip() for line in xml.readlines()])\\\n",
    "                        .replace(\"<\", \"#!#<\")\\\n",
    "                        .replace(\">\", \">#!#\")\\\n",
    "                        .split(\"#!#\")\n",
    "        for elem in data:\n",
    "            if TagRE.match(elem):\n",
    "                name = elem.split(' ')[0]\n",
    "                result_set.add(name)\n",
    "                COUNTER2 +=1\n",
    "\n",
    "for xmlfile in glob(SRC_DIR+'/**/*grc*.xml', recursive=True):\n",
    "    COUNTER +=1\n",
    "#     tm.info(f'parsing {xmlfile}')\n",
    "#     authorWork(xmlfile)\n",
    "#     refsDecl(xmlfile)\n",
    "#     cRefPattern(xmlfile)\n",
    "#     state(xmlfile)\n",
    "#     findRefDecl(xmlfile)\n",
    "#     step(xmlfile)\n",
    "#     readfile(xmlfile)\n",
    "#     findDivs(xmlfile)\n",
    "    findOpenTags(xmlfile)\n",
    "pprint(result_set)\n",
    "tm.info('--> Total Time')\n",
    "print(f'{COUNTER} works have been parsed...')\n",
    "print(f'{COUNTER2} works show a problem...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "string = StringIO('''                    <l n=\"1\">\n",
    "                  <said who=\"#Ἀμφιτρύων\">Τίς τὸν Διὸς σύλλεκτρον οὐκ οἶδεν βροτῶν,</said>\n",
    "               </l>\n",
    "               <l n=\"2\">\n",
    "                  <said who=\"#Ἀμφιτρύων\">Ἀργεῖον Ἀμφιτρύωνʼ, ὃν Ἀλκαῖός ποτε</said>\n",
    "               </l>\n",
    "               <l n=\"3\">\n",
    "                  <said who=\"#Ἀμφιτρύων\">ἔτιχθʼ ὁ Περσέως, πατέρα τόνδʼ Ἡρακλέους;   </said>\n",
    "               </l>\n",
    "               <l n=\"4\">\n",
    "                  <said who=\"#Ἀμφιτρύων\">ὃς τάσδε Θήβας ἔσχον, ἔνθʼ ὁ γηγενὴς</said>\n",
    "               </l>\n",
    "''')\n",
    "data = ' '.join([line.strip() for line in string.readlines()])\\\n",
    "                        .replace(\"<\", \"#!#<\")\\\n",
    "                        .replace(\">\", \">#!#\")\\\n",
    "                        .split(\"#!#\")\n",
    "print(data)\n",
    "lis = []\n",
    "for elem in data:\n",
    "    elem = elem.strip()\n",
    "    if elem == '':\n",
    "#     if bool(elem) == False:\n",
    "        continue\n",
    "    else: \n",
    "        lis.append(elem)\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio = {'biblStruct': {'author': 'Galen', \n",
    "                         'title': 'On the Natural Faculties', \n",
    "                         'editor': 'J.K. Elliot', \n",
    "                         'publisher': 'Oxford University Press', \n",
    "                         'date': '2013'}\n",
    "         }\n",
    "description = ', '.join([v for k, v in dictio['biblStruct'].items()])\n",
    "print(description)\n",
    "\n",
    "for k, v in dictio['biblStruct'].items():\n",
    "    if k.startswith('editor'):\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ['SourceDesc', 'Biblstmt']\n",
    "for i in string:\n",
    "    if 'ource' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "book = 'Description of Greece (Greek). Machine readable text (Greek)'\n",
    "# book = 'Annotations. (Greek)'\n",
    "print(book)\n",
    "book = book.replace('(Greek)', '').replace('.', '').replace('Machine readable text', '')\n",
    "# book = book.strip(\"('(Greek)', '.', ',', 'Machine Readible Text')\")\n",
    "# replace_all(book, {'Greek': ''})\n",
    "\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = '<author ref=\"http://data.perseus.org/catalog/urn:cts:greekLit:tlg2200\">Libanius</author>'\n",
    "tag_split = elem.find(' ') if not elem.find(' ') == -1 else elem.find('>')\n",
    "print(elem[1:tag_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = dict(\n",
    "    sentence=0,\n",
    "    word=0,\n",
    "    letter=15)\n",
    "\n",
    "tag_name = 'letter'\n",
    "\n",
    "print(counter)\n",
    "counter[tag_name] = 1 if tag_name not in counter else counter[tag_name] + 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = ['2', '3', ' 56', '54', '45', '67', '3']\n",
    "all(y.strip().isdigit() for y in lis)\n",
    "\n",
    "for x.startswith('5') in lis:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()\n",
    "lis = [1, 2, 3, 4]\n",
    "a.update(lis)\n",
    "print(a)\n",
    "\n",
    "intFeatures = {'section', 'number'}\n",
    "\n",
    "x = 'section'\n",
    "y = 'chapter'\n",
    "\n",
    "result = f'book, {\"number\" if x in intFeatures else \"label\"}'\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "REPO = '~/github/pthu/patristics'\n",
    "SRC_DIR = SRC_DIR = path.expanduser(f'{REPO}/sources/pt/tlg2021/tlg001/tlg2021.tlg001.opp-grc1.xml') \n",
    "\n",
    "class Data:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data = self.dataFinder(self.path)\n",
    "        \n",
    "    def dataFinder(self, path):\n",
    "        with open(path) as xml:\n",
    "            data = ' '.join([line.strip() for line in xml.readlines()])\\\n",
    "                      .replace('<', '#!#<')\\\n",
    "                      .replace('>', '>#!#')\\\n",
    "                      .split('#!#')\n",
    "\n",
    "        return data\n",
    "\n",
    "x = Data(SRC_DIR)\n",
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio = {1: {1:1}, 2: {2:2}}\n",
    "print(dictio)\n",
    "dictio1 = {k: v for k,  in dictio.items() for key: len(value) in v.items()}\n",
    "print(dictio1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "elem = '<gap reason  =  \"                                 omitted\"/>'\n",
    "print(elem)\n",
    "elem = re.sub(r'\\s*=\\s*\"\\s*', '=\"', elem)\n",
    "print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'abcdefg'\n",
    "if string.startswith(('b', 'a')):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.lemmatize.greek.backoff import BackoffGreekLemmatizer\n",
    "\n",
    "# lemmatizer = BackoffGreekLemmatizer()\n",
    "\n",
    "sentence = 'τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲν εὑρεῖν διὰ χρόνου πλῆθος ἀδύνατα ἦν'\n",
    "\n",
    "lemmatizer = LemmaReplacer('greek')\n",
    "lemmatizer.lemmatize(sentence, return_string=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import betacode.conv\n",
    "\n",
    "string = '''*polla/ me ta\\ parakalou=nta/ e)sti cumbouleu=sai\n",
    "u(mi=n, w)= pai=des, a(\\ be/ltista ei)=nai kri/nw,\n",
    "kai\\ a(\\ cunoi/sein u(mi=n e(lome/nois pepi/steuka. to/\n",
    "te ga\\r h(liki/as ou(/tws e)/xein kai\\ to\\ dia\\ pollw=n\n",
    "h)/dh gegumna/sqai pragma/twn kai\\ mh\\n kai\\ to\\\n",
    "th=s pa/nta paideuou/shs e)p) a)/mfw metabolh=s\n",
    "i(kanw=s metasxei=n, e)/mpeiro/n me ei)=nai tw=n a)nqrwpi/nwn\n",
    "pepoi/hken, w(/ste toi=s a)/rti kaqistame/nois\n",
    "to\\n bi/on e)/xein w(/sper o(dw=n th\\n a)sfalesta/thn\n",
    "u(podeiknu/nai.'''\n",
    "\n",
    "print(betacode.conv.beta_to_uni(string, strict=True))\n",
    "\n",
    "string1 = 'τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲν εὑρεῖν διὰ χρόνου πλῆθος ἀδύνατα ἦν'\n",
    "\n",
    "string1.encode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Origin of Species. (Greek) Machine Readible Text'\n",
    "string = string.strip(\"'(Greek)', '.', ',', 'Machine Readible Text'}\")\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 'pseudo-justinus martyr'\n",
    "st.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "ELISION = {'ἀλλ᾽': 'ἀλλὰ', 'ἀλλʼ': 'ἀλλὰ', 'ἐφ᾽': 'ἐπὶ', 'διʼ': 'διά', 'τ᾽': 'τέ', 'δ᾽': 'δέ', 'γ᾽': 'γέ', 'ὅτ᾽': 'ὅτε', 'ἐπ᾽': 'ἐπὶ', 'ἀνθ᾽': 'ἀντὶ', 'ὑπ᾽': 'ὑπο', 'ἔσθ᾽': 'ἐστὶν', 'οὐδ᾽': 'οὐδέ', 'ἀφ᾽': 'ἀπό', 'καθ᾽': 'κατά', 'μεθ᾽': 'μετά',}\n",
    "\n",
    "ELISION1 = {normalize('NFC', k): normalize('NFC', v) for k, v in ELISION.items()}\n",
    "\n",
    "print(ELISION1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ('milestone', ('unit', 'n', 'rend'))\n",
    "if st[0].startswith(('div', 'milestone')):\n",
    "    print(\"yes\")\n",
    "if all(i in st[1] for i in ('unit', 'n')):\n",
    "    print(\"yes again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = ['chapter']\n",
    "lis1 = ('section', 'subsection')\n",
    "lis.extend(lis1)\n",
    "print(lis)\n",
    "print(lis[1:])\n",
    "lis.index('chapter')\n",
    "print(lis[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = []\n",
    "if lsi:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3\n"
     ]
    }
   ],
   "source": [
    "tup = (1, 3, 5)\n",
    "print(\".\".join((str(i) for i in tup[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
