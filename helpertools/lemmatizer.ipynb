{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lemmatizer of Greek text\n",
    "\n",
    "This file provides a function (createLemmatizer) that creates (pickles) a dictionary that contains Greek wordforms as its keys and its possible lemmata as values (set). It also provides a function (lemmatize) that takes two arguments: a wordstring and the just created dictionary of lemmata. It returns a string with the possible lemmata in comma-separated format.\n",
    "\n",
    "If you like to use these functions, be aware to load the lemmatizer (=lemma dictionary) only once...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from unicodedata import normalize, category\n",
    "from os import path\n",
    "from pprint import pprint\n",
    "import xml.etree.ElementTree as etree\n",
    "from tf.fabric import Timestamp\n",
    "import nbimporter\n",
    "\n",
    "udnorm = 'NFD'\n",
    "\n",
    "REPO = '~/github/pthu/patristics'\n",
    "SRC_DIR = path.expanduser(f'{REPO}/programs/helpertools/data')\n",
    "SOURCE1 = SRC_DIR + '/forms-normalised-20180208_001.txt'\n",
    "SOURCE2 = SRC_DIR + '/MorpheusUnicode.xml'\n",
    "\n",
    "letter = {'L'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_FORMS = {\n",
    "    'θεὸς': 'θεός',\n",
    "    'ἰδοὺ': 'ἰδοὺ',\n",
    "    'ἐμὲ': 'ἐμός',\n",
    "    'τάυτην': 'οὗτος',\n",
    "    'εὐλογημένος': 'εὐλογέω',\n",
    "    'δαβίδ': 'δαβίδ',\n",
    "    'ὡσαννά': 'ὡσαννά',\n",
    "    'ἐγὼ': 'ἐγώ',\n",
    "    'μωσέως': 'μωσέως',\n",
    "    'ἱερουσαλήμ': 'ἱερουσαλήμ',\n",
    "    'ἔρχεταί': 'ἔρχομαι',\n",
    "    'ἡσαΐου': 'ἡσαΐου',\n",
    "    'ἰσαὰκ': 'ἰσαὰκ'\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(word):\n",
    "    return ''.join(c for c in normalize(udnorm, word.lower())\n",
    "                   if category(c)[0] in letter)\n",
    "\n",
    "def createLemmatizer(sourcepath1, sourcepath2):\n",
    "    lemma_dict = {}\n",
    "    with open(sourcepath1) as source1:\n",
    "        for line in source1:\n",
    "            form, alternative, morphology, lemma = line.strip().split(\"\\t\")\n",
    "            form1 = normalize(udnorm, form.lower())\n",
    "            form2 = strip_accents(form1)\n",
    "            alternative1 = normalize(udnorm, alternative.lower())\n",
    "            alternative2 = strip_accents(alternative1)\n",
    "            lemma = normalize(udnorm, lemma.lower())\n",
    "            if form1 in lemma_dict:\n",
    "                lemma_dict[form1].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form1] = {lemma}\n",
    "            if form2 in lemma_dict:\n",
    "                lemma_dict[form2].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form2] = {lemma}\n",
    "                \n",
    "            if alternative1 in lemma_dict:\n",
    "                lemma_dict[alternative1].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[alternative1] = {lemma}\n",
    "            if alternative2 in lemma_dict:\n",
    "                lemma_dict[alternative2].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[alternative2] = {lemma}\n",
    "                \n",
    "    with open(sourcepath2) as source2:\n",
    "        tree = etree.parse(source2)\n",
    "        for elem in tree.iter('t'):\n",
    "            form1a = normalize(udnorm, elem.findtext('f').lower())\n",
    "            form2a = normalize(udnorm, elem.findtext('b').lower())\n",
    "            form1b = strip_accents(elem.findtext('f').lower())\n",
    "            form2b = strip_accents(elem.findtext('b').lower())\n",
    "            lemma = normalize(udnorm, elem.findtext('l').lower())\n",
    "            if form1a in lemma_dict:\n",
    "                lemma_dict[form1a].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form1a] = {lemma}\n",
    "            if form2a in lemma_dict:\n",
    "                lemma_dict[form2a].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form2a] = {lemma}\n",
    "                \n",
    "            if form1b in lemma_dict:\n",
    "                lemma_dict[form1b].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form1b] = {lemma}\n",
    "            if form2b in lemma_dict:\n",
    "                lemma_dict[form2b].add(lemma)\n",
    "            else:\n",
    "                lemma_dict[form2b] = {lemma}\n",
    "        tree = None\n",
    "        \n",
    "    from data.greek_lemmata_cltk import LEMMATA\n",
    "        \n",
    "    for key, value in LEMMATA.items():\n",
    "        formA = normalize(udnorm, key.lower())\n",
    "        formB = strip_accents(key.lower())\n",
    "        lemma = normalize(udnorm, value.lower())\n",
    "        if formA in lemma_dict:\n",
    "            lemma_dict[formA].add(lemma)\n",
    "        else:\n",
    "            lemma_dict[formA] = {lemma}\n",
    "        if formB in lemma_dict:\n",
    "            lemma_dict[formB].add(lemma)\n",
    "        else:\n",
    "            lemma_dict[formB] = {lemma}\n",
    "            \n",
    "    for key, value in MANUAL_FORMS.items():\n",
    "        formA = normalize(udnorm, key.lower())\n",
    "        formB = strip_accents(key.lower())\n",
    "        lemma = normalize(udnorm, value.lower())\n",
    "        if formA in lemma_dict:\n",
    "            lemma_dict[formA].add(lemma)\n",
    "        else:\n",
    "            lemma_dict[formA] = {lemma}\n",
    "        if formB in lemma_dict:\n",
    "            lemma_dict[formB].add(lemma)\n",
    "        else:\n",
    "            lemma_dict[formB] = {lemma}\n",
    "    \n",
    "    # Handle movable-nu and final-sigma\n",
    "    lemma_dict_add = {}\n",
    "    for wordform in lemma_dict:\n",
    "        if wordform.endswith(('εν', 'σιν', 'στιν')):\n",
    "            if wordform[:-1] in lemma_dict:\n",
    "                pass\n",
    "            else:\n",
    "                lemma_dict_add[wordform[:-1]] = lemma_dict[wordform]\n",
    "        elif wordform.endswith('σ'):\n",
    "            if wordform[:-1] + 'ς' in lemma_dict:\n",
    "                pass\n",
    "            else:\n",
    "                lemma_dict_add[wordform[:-1] + 'ς'] = lemma_dict[wordform]\n",
    "    lemma_dict.update(lemma_dict_add)\n",
    "    \n",
    "    with open(SRC_DIR + '/lemmatizer.pickle', 'wb') as lemmatizer:\n",
    "        pickle.dump(lemma_dict, lemmatizer, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Run the creation process    \n",
    "# createLemmatizer(SOURCE1, SOURCE2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize(word, lemmatizer):\n",
    "    word = normalize('NFD', word.lower())\n",
    "    if word in lemmatizer:\n",
    "        word = ','.join(lemmatizer[word])\n",
    "    else:\n",
    "        word = f'*{word}'\n",
    "    return word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ʼβόησε': {'βοάω'},\n",
      " 'ʼβοησε': {'βοάω'},\n",
      " 'ʼβολοστάται': {'ὀβολοστάτης'},\n",
      " 'ʼβολοσταται': {'ὀβολοστάτης'},\n",
      " 'ʼγαθε': {'ἀγαθός'},\n",
      " 'ʼγαθέ': {'ἀγαθός'},\n",
      " 'ʼγαθοι': {'ἀγαθός'},\n",
      " 'ʼγαθοί': {'ἀγαθός'},\n",
      " 'ʼγγελᾶν': {'ἀναγελάω', 'ἐγγελάω'},\n",
      " 'ʼγγελαν': {'ἀναγελάω', 'ἐγγελάω'},\n",
      " 'ʼγγύθε': {'ἐγγύς'},\n",
      " 'ʼγγύθεν': {'ἐγγύς'},\n",
      " 'ʼγγυθε': {'ἐγγύς'},\n",
      " 'ʼγγυθεν': {'ἐγγύς'},\n",
      " 'ʼγω': {'ἀγός'},\n",
      " 'ʼγώ': {'ἀγός'},\n",
      " 'ʼδάκρυσα': {'δακρύω'},\n",
      " 'ʼδάμη': {'δαμάζω'},\n",
      " 'ʼδακρυσα': {'δακρύω'},\n",
      " 'ʼδαμη': {'δαμάζω'},\n",
      " 'ʼδικεῖν': {'ἀδικέω'},\n",
      " 'ʼδικειν': {'ἀδικέω'},\n",
      " 'ʼδόκουν': {'δοκέω'},\n",
      " 'ʼδοκουν': {'δοκέω'},\n",
      " 'ʼδυνήθημε': {'δύναμαι'},\n",
      " 'ʼδυνήθημεν': {'δύναμαι'},\n",
      " 'ʼδυνηθημε': {'δύναμαι'},\n",
      " 'ʼδυνηθημεν': {'δύναμαι'},\n",
      " 'ʼδυστύχησε': {'δυστυχέω'},\n",
      " 'ʼδυστύχησεν': {'δυστυχέω'},\n",
      " 'ʼδυστυχησε': {'δυστυχέω'},\n",
      " 'ʼδυστυχησεν': {'δυστυχέω'},\n",
      " 'ʼδωκε': {'δίδωμι'},\n",
      " 'ʼδωκεν': {'δίδωμι'},\n",
      " 'ʼθάνον': {'ἀποθνῄσκω'},\n",
      " 'ʼθανον': {'ἀποθνῄσκω'},\n",
      " 'ʼθέλειν': {'ἐθέλω'},\n",
      " 'ʼθέλεις': {'ἐθέλω'},\n",
      " 'ʼθέλῃ': {'ἐθέλω'},\n",
      " 'ʼθέλοιμε': {'ἐθέλω'},\n",
      " 'ʼθέλοιμεν': {'ἐθέλω'},\n",
      " 'ʼθέλοις': {'ἐθέλω'},\n",
      " 'ʼθέλω': {'ἐθέλω'},\n",
      " 'ʼθελειν': {'ἐθέλω'},\n",
      " 'ʼθελεις': {'ἐθέλω'},\n",
      " 'ʼθελη': {'ἐθέλω'},\n",
      " 'ʼθελοιμε': {'ἐθέλω'},\n",
      " 'ʼθελοιμεν': {'ἐθέλω'},\n",
      " 'ʼθελοις': {'ἐθέλω'},\n",
      " 'ʼθελοντής': {'ἐθελοντής'},\n",
      " 'ʼθελοντης': {'ἐθελοντής'},\n",
      " 'ʼθελω': {'ἐθέλω'},\n",
      " 'ʼθιγες': {'θιγγάνω'},\n",
      " 'ʼθώϋξε': {'θωΰσσω'},\n",
      " 'ʼθώϋξεν': {'θωΰσσω'},\n",
      " 'ʼθωυξε': {'θωΰσσω'},\n",
      " 'ʼθωυξεν': {'θωΰσσω'},\n",
      " 'ʼκ': {'ἐκ'},\n",
      " 'ʼκάλεσας': {'καλέω'},\n",
      " 'ʼκάλυψα': {'καλύπτω'},\n",
      " 'ʼκαλεῖτο': {'καλέω'},\n",
      " 'ʼκαλειτο': {'καλέω'},\n",
      " 'ʼκαλεσας': {'καλέω'},\n",
      " 'ʼκαλυψα': {'καλύπτω'},\n",
      " 'ʼκδούς': {'ἐκδίδωμι'},\n",
      " 'ʼκδους': {'ἐκδίδωμι'},\n",
      " 'ʼκδύομαι': {'ἐκδύω'},\n",
      " 'ʼκδυομαι': {'ἐκδύω'},\n",
      " 'ʼκέλευσα': {'κελεύω'},\n",
      " 'ʼκείνη': {'ἐκεῖνος'},\n",
      " 'ʼκείνου': {'ἐκεῖνος'},\n",
      " 'ʼκείνους': {'ἐκεῖνος'},\n",
      " 'ʼκείνῳ': {'ἐκεῖνος'},\n",
      " 'ʼκείνων': {'ἐκεῖνος'},\n",
      " 'ʼκεῖνοι': {'ἐκεῖνος'},\n",
      " 'ʼκεῖνον': {'ἐκεῖνος'},\n",
      " 'ʼκεῖνος': {'ἐκεῖνος'},\n",
      " 'ʼκεινη': {'ἐκεῖνος'},\n",
      " 'ʼκεινοι': {'ἐκεῖνος'},\n",
      " 'ʼκεινον': {'ἐκεῖνος'},\n",
      " 'ʼκεινος': {'ἐκεῖνος'},\n",
      " 'ʼκεινου': {'ἐκεῖνος'},\n",
      " 'ʼκεινους': {'ἐκεῖνος'},\n",
      " 'ʼκεινω': {'ἐκεῖνος'},\n",
      " 'ʼκεινων': {'ἐκεῖνος'},\n",
      " 'ʼκελευσα': {'κελεύω'},\n",
      " 'ʼκκοπῇς': {'ἐκκόπτω'},\n",
      " 'ʼκκοπης': {'ἐκκόπτω'},\n",
      " 'ʼκλαιε': {'κλαίω'},\n",
      " 'ʼκλιπεῖν': {'ἐκλείπω'},\n",
      " 'ʼκλιπειν': {'ἐκλείπω'},\n",
      " 'ʼκμαθεῖν': {'ἐκμανθάνω'},\n",
      " 'ʼκμαθειν': {'ἐκμανθάνω'},\n",
      " 'ʼκοινωσάμην': {'κοινόω'},\n",
      " 'ʼκοινωσαμην': {'κοινόω'},\n",
      " 'ʼκπλαγέντες': {'ἐκπλήσσω'},\n",
      " 'ʼκπλαγεντες': {'ἐκπλήσσω'},\n",
      " 'ʼκράτησα': {'κρατέω'},\n",
      " 'ʼκρατησα': {'κρατέω'},\n",
      " 'ʼκτανον': {'κτείνω'}}\n",
      "'The total number of available wordforms = 2029891'\n"
     ]
    }
   ],
   "source": [
    "# Small test setup\n",
    "\n",
    "lemmatizer_open = open(SRC_DIR + '/lemmatizer.pickle', 'rb')\n",
    "lemmatizer = pickle.load(lemmatizer_open)\n",
    "\n",
    "selection = {k: v for k, v in sorted(lemmatizer.items())[:100]}\n",
    "pprint(selection)\n",
    "pprint(f'The total number of available wordforms = {len(lemmatizer)}')\n",
    "\n",
    "lemmatize('ἐΠράχθη', lemmatizer)\n",
    "lemmatizer_open.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
