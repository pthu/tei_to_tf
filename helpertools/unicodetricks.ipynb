{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greek Unicode tricks\n",
    "\n",
    "In this notebook, we explore how the unicodedata library works and how we can use it to convert Greek text to a number of formats. An important function is also to split punctuation from words even if it occurs in the middle of a word. \n",
    "\n",
    "(A lot of code in this notebook has originally been written by Dirk Roorda for which I am very thankful. Afterwards, I have done my own job with it and adjusted the original code here and there.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from unicodedata import category, normalize\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we show the available categories of unicode characters available in the unicodedata library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the available categories in the unicodedata library:\n",
      "{'Cc': 'Other, Control',\n",
      " 'Cf': 'Other, Format',\n",
      " 'Cn': 'Other, Not Assigned (no characters in the file have this property)',\n",
      " 'Co': 'Other, Private Use',\n",
      " 'Cs': 'Other, Surrogate',\n",
      " 'LC': 'Letter, Cased',\n",
      " 'Ll': 'Letter, Lowercase',\n",
      " 'Lm': 'Letter, Modifier',\n",
      " 'Lo': 'Letter, Other',\n",
      " 'Lt': 'Letter, Titlecase',\n",
      " 'Lu': 'Letter, Uppercase',\n",
      " 'Mc': 'Mark, Spacing Combining',\n",
      " 'Me': 'Mark, Enclosing',\n",
      " 'Mn': 'Mark, Nonspacing',\n",
      " 'Nd': 'Number, Decimal Digit',\n",
      " 'Nl': 'Number, Letter',\n",
      " 'No': 'Number, Other',\n",
      " 'Pc': 'Punctuation, Connector',\n",
      " 'Pd': 'Punctuation, Dash',\n",
      " 'Pe': 'Punctuation, Close',\n",
      " 'Pf': 'Punctuation, Final quote (may behave like Ps or Pe depending on usage)',\n",
      " 'Pi': 'Punctuation, Initial quote (may behave like Ps or Pe depending on '\n",
      "       'usage)',\n",
      " 'Po': 'Punctuation, Other',\n",
      " 'Ps': 'Punctuation, Open',\n",
      " 'Sc': 'Symbol, Currency',\n",
      " 'Sk': 'Symbol, Modifier',\n",
      " 'Sm': 'Symbol, Math',\n",
      " 'So': 'Symbol, Other',\n",
      " 'Zl': 'Separator, Line',\n",
      " 'Zp': 'Separator, Paragraph',\n",
      " 'Zs': 'Separator, Space'}\n"
     ]
    }
   ],
   "source": [
    "# Show dictionary with all unicode categories\n",
    "open_dict = open(\"data/unicode_cat_dict.pickle\",\"rb\")\n",
    "unicode_cat_dict = pickle.load(open_dict)\n",
    "print('These are the available categories in the unicodedata library:')\n",
    "pprint(unicode_cat_dict)\n",
    "\n",
    "open_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now process some (poluted) Greek words and categorize the various characters present in these words. Also the difference between combined characters with accents and uncombined characters with accents will be shown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll']\n",
      "['Α', 'υ', '̓', 'τ', 'ο', 'υ', '́', 'ς', '·', 'Α', 'υ', '̓', 'τ', 'ο', 'υ', '́', 'ς']\n",
      "['Lu', 'Ll', 'Mn', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Po', 'Lu', 'Ll', 'Mn', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll']\n",
      "\n",
      "\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Mn', 'Ll']\n",
      "['Σ', 'ι', 'λ', 'ω', 'α', '́', 'μ', '?', '̔', 'ο', '̔', '̀']\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Po', 'Mn', 'Ll', 'Mn', 'Mn']\n",
      "\n",
      "\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Mn']\n",
      "['Δ', 'ι', 'δ', 'α', '́', 'σ', 'κ', 'α', 'λ', 'ε', '?', '̓']\n",
      "['Lu', 'Ll', 'Ll', 'Ll', 'Mn', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Mn']\n",
      "\n",
      "\n",
      "['Po', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Po', 'Zs', 'Ll', 'Ll', 'Zs', 'Ll', 'Ll', 'Po', 'Zs', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Sm', 'Ll', 'Ll', 'Ll', 'Po', 'Zs', 'Ll', 'Pe', 'Ll', 'Ll', 'Ll', 'Zs', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Sm', 'Ll', 'Ll', 'Ll', 'Zs', 'Ll', 'Ps', 'Ll', 'Ll', 'Sm', 'Ll']\n",
      "['Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Ll', 'Sm', 'Ll', 'Ll', 'Ll']\n"
     ]
    }
   ],
   "source": [
    "word1 = 'Αὐτούς·Αὐτούς'\n",
    "word2 = 'Σιλωάμ?̔ὃ'\n",
    "word3 = 'Διδάσκαλε?̓'\n",
    "sen1 = 'ἄλογοι«, δι᾿ «ὧν« δῆλον ὅτι αἱ ἁμαρτίαι «μηνύονται« αἱ μὴ γεγονυῖαι κατὰ λόγον.'\n",
    "sen2 = '*polla/ me ta\\ parakalou=nta/ e)sti cumbouleu=sai u(mi=n'\n",
    "\n",
    "for word in (word1, word2, word3):\n",
    "    print([category(x) for x in word])\n",
    "    print([x for x in normalize('NFD', word)])\n",
    "    print([category(x) for x in normalize('NFD', word)])\n",
    "    print('\\n')\n",
    "print([category(x) for x in sen2])\n",
    "print([category(x) for x in 'cumbouleu=sai'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a number of functions to process Greek text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter = {'L'}\n",
    "letter_space = {'L', 'Z'}\n",
    "dia = {'M'}\n",
    "punc = {'P'}\n",
    "letter_dia = {'L', 'M'}\n",
    "\n",
    "NFD = 'NFD'\n",
    "NFC = 'NFC'\n",
    "\n",
    "\n",
    "def splitPuncSimple(w):\n",
    "    afterWord = len(w)\n",
    "    for i in range(len(w) - 1, -1, -1):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            afterWord = i\n",
    "        else:\n",
    "            break\n",
    "    return (w[0:afterWord], w[afterWord:]+' ')\n",
    "\n",
    "def splitPunc(w):\n",
    "    pP = 0\n",
    "    for i in range(len(w)):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            pP += 1\n",
    "        else:\n",
    "            break\n",
    "    preWord = w[0:pP] if pP else ''\n",
    "    pW = pP\n",
    "    for i in range(pP, len(w)):\n",
    "        if category(w[i])[0] in letter:\n",
    "            pW += 1\n",
    "        else:\n",
    "            break\n",
    "    word = w[pP:pW]\n",
    "    pA = pW\n",
    "    for i in range(pW, len(w)):\n",
    "        if category(w[i])[0] not in letter:\n",
    "            pA += 1\n",
    "        else:\n",
    "            break\n",
    "    afterWord = w[pW:pA]\n",
    "    if pA == len(w):\n",
    "        afterWord += ' '\n",
    "    \n",
    "    rest = splitPunc(w[pA:]) if pA < len(w) else ()\n",
    "    return ((preWord, word, afterWord),) + rest\n",
    "\n",
    "def Tokenizer(sentence, udnorm='NFD'): \n",
    "    sen = normalize(udnorm, sentence)\n",
    "    words = sen.split(' ')\n",
    "    tokens = []\n",
    "    tokenized_sentence = []\n",
    "    for w in words:\n",
    "        pP = 0\n",
    "        for i in range(len(w)):\n",
    "            if category(w[i])[0] not in letter_dia:\n",
    "                pP += 1\n",
    "            else:\n",
    "                break\n",
    "        preWord = w[0:pP] if pP else ''\n",
    "        pW = pP\n",
    "        for i in range(pP, len(w)):\n",
    "            if category(w[i])[0] in letter_dia:\n",
    "                pW += 1\n",
    "            else:\n",
    "                break\n",
    "        word = w[pP:pW]\n",
    "        pA = pW\n",
    "        for i in range(pW, len(w)):\n",
    "            if category(w[i])[0] not in letter_dia:\n",
    "                pA += 1\n",
    "            else:\n",
    "                break\n",
    "        afterWord = w[pW:pA]\n",
    "        tokens = [word] + ([w[pA:]] if pA < len(w) else [])\n",
    "        tokenized_sentence += tokens        \n",
    "    return tokenized_sentence  \n",
    "    \n",
    "\n",
    "def plainMajuscule(sentence):\n",
    "    return ''.join(x.upper() for x in normalize('NFD', ' '.join(sentence)) if category(x)[0] not in dia)\n",
    "\n",
    "def plainMinuscule(sentence):\n",
    "    return ''.join(x.lower() for x in normalize('NFD', ' '.join(sentence)) if category(x)[0] not in dia)\n",
    "\n",
    "def plainCaps(w):\n",
    "    return ''.join(x.upper() for x in normalize(NFD, w) if category(x)[0] in letter)\n",
    "\n",
    "def plainLow(w):\n",
    "    return ''.join(x.lower() for x in normalize(NFD, w) if category(x)[0] in letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do some texts to show how it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('..', '', ' '),)\n",
      "ΑΛΟΓΟΙ ΔΙ ΩΝ ΔΗΛΟΝ ΟΤΙ ΑΙ ΑΜΑΡΤΙΑΙ ΜΗΝΥΟΝΤΑΙ ΑΙ ΜΗ ΓΕΓΟΝΥΙΑΙ ΚΑΤΑ ΛΟΓΟΝ\n",
      "αλογοι δι ων δηλον οτι αι αμαρτιαι μηνυονται αι μη γεγονυιαι κατα λογον\n"
     ]
    }
   ],
   "source": [
    "print(splitPunc('.'))\n",
    "\n",
    "wordBare = Tokenizer(sen1, udnorm='NFD')\n",
    "\n",
    "wordPlainMajuscule = plainMajuscule(wordBare)\n",
    "print(wordPlainMajuscule)\n",
    "\n",
    "wordPlainMinuscule = plainMinuscule(wordBare)\n",
    "print(wordPlainMinuscule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lm\n"
     ]
    }
   ],
   "source": [
    "print(category('ʼ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
